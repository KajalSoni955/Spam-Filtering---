{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam Filtering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6AuJKJ8UWzD"
      },
      "source": [
        "**Natural Language Processing for Text Classification with NLTK and Scikit-learn**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeCESUlJW6tc"
      },
      "source": [
        "1.imports and loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkZPgJRpU1Nc"
      },
      "source": [
        "#imports\r\n",
        "import sys\r\n",
        "import nltk\r\n",
        "import sklearn\r\n",
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "P0o8KsqCVbtV",
        "outputId": "7907ee53-09d3-4f5a-c589-bace05c6b34a"
      },
      "source": [
        "from google.colab import files\r\n",
        "uploaded = files.upload()\r\n",
        "df =pd.read_table(\"SMSSpamCollection\", header=None, encoding='utf-8')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0a093870-e5f3-47c8-bf13-13b4387624e0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0a093870-e5f3-47c8-bf13-13b4387624e0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving SMSSpamCollection to SMSSpamCollection (1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF1mkzOJWj7Z",
        "outputId": "15d78674-2f66-446f-b026-075dd04efb86"
      },
      "source": [
        "print(df.info())\r\n",
        "print(df.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       5572 non-null   object\n",
            " 1   1       5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "None\n",
            "      0                                                  1\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdzADn1aWmea",
        "outputId": "ed7c0483-3fef-45a5-839a-2481bc4b534a"
      },
      "source": [
        "print(df[0].count())\r\n",
        "print(df[0].value_counts())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5572\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-tuP6U_XCKj"
      },
      "source": [
        "2.preprocessing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCmJA63oXXnI"
      },
      "source": [
        "*-> we will convert our class labels to binary values using the LabelEncoder from sklearn, \r\n",
        "-> replace email addresses, URLs, phone numbers, and other symbols by using regular expressions, \r\n",
        "-> remove stop words, and extract word stems.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGmexyNTXhYh",
        "outputId": "7be595e6-81a5-4d43-dad6-c9437fe656d1"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "encoder =LabelEncoder()\r\n",
        "Y=encoder.fit_transform(df[0])\r\n",
        "print (Y[:10])   #ham=0, spam=1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 0 0 1 0 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zS348aF9X870",
        "outputId": "e8c3ed9d-53cf-4d2c-f6ed-d8d065ef769b"
      },
      "source": [
        "text_messages = df[1]\r\n",
        "df[1].head(10)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Go until jurong point, crazy.. Available only ...\n",
              "1                        Ok lar... Joking wif u oni...\n",
              "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    U dun say so early hor... U c already then say...\n",
              "4    Nah I don't think he goes to usf, he lives aro...\n",
              "5    FreeMsg Hey there darling it's been 3 week's n...\n",
              "6    Even my brother is not like to speak with me. ...\n",
              "7    As per your request 'Melle Melle (Oru Minnamin...\n",
              "8    WINNER!! As a valued network customer you have...\n",
              "9    Had your mobile 11 months or more? U R entitle...\n",
              "Name: 1, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf5EehmjYJXy"
      },
      "source": [
        "# use regular expressions to replace email addresses, URLs, phone numbers, other numbers\r\n",
        "\r\n",
        "# Replace email addresses with 'email'\r\n",
        "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\r\n",
        "                                 'emailaddress')\r\n",
        "\r\n",
        "# Replace URLs with 'webaddress'\r\n",
        "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\r\n",
        "                                  'webaddress')\r\n",
        "\r\n",
        "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\r\n",
        "processed = processed.str.replace(r'£|\\$', 'moneysymb')\r\n",
        "    \r\n",
        "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\r\n",
        "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\r\n",
        "                                  'phonenumbr')\r\n",
        "    \r\n",
        "# Replace numbers with 'numbr'\r\n",
        "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9mwJjqLYVSy"
      },
      "source": [
        "# Remove punctuation\r\n",
        "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\r\n",
        "\r\n",
        "# Replace whitespace between terms with a single space\r\n",
        "processed = processed.str.replace(r'\\s+', ' ')\r\n",
        "\r\n",
        "# Remove leading and trailing whitespace\r\n",
        "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czVwQonOYdrN",
        "outputId": "119d47c3-3b88-48f4-da0e-a7bdccb37f79"
      },
      "source": [
        "# change words to lower case - Hello, HELLO, hello are all the same word\r\n",
        "processed = processed.str.lower()\r\n",
        "print(processed.head(10))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    go until jurong point crazy available only in ...\n",
            "1                              ok lar joking wif u oni\n",
            "2    free entry in numbr a wkly comp to win fa cup ...\n",
            "3          u dun say so early hor u c already then say\n",
            "4    nah i don t think he goes to usf he lives arou...\n",
            "5    freemsg hey there darling it s been numbr week...\n",
            "6    even my brother is not like to speak with me t...\n",
            "7    as per your request melle melle oru minnaminun...\n",
            "8    winner as a valued network customer you have b...\n",
            "9    had your mobile numbr months or more u r entit...\n",
            "Name: 1, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmbysi-gYk1Z",
        "outputId": "97eb4e22-4db8-4d82-a437-76d47c9da9dd"
      },
      "source": [
        "#Remove stop words\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "stop_words = set(stopwords.words('english'))\r\n",
        "\r\n",
        "processed = processed.apply(lambda x: ' '.join(\r\n",
        "    term for term in x.split() if term not in stop_words))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZi1LtQeZJyG"
      },
      "source": [
        "# Remove word stems \r\n",
        "ps = nltk.PorterStemmer()\r\n",
        "\r\n",
        "processed = processed.apply(lambda x: ' '.join(\r\n",
        "    ps.stem(term) for term in x.split()))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO3g4FquaP50",
        "outputId": "7339a441-4bfb-461e-e236-e6cb4bd95a19"
      },
      "source": [
        "#tokenizing for ML algorithms\r\n",
        "nltk.download('punkt')\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "\r\n",
        "# create bag-of-words\r\n",
        "all_words = []\r\n",
        "\r\n",
        "for message in processed:\r\n",
        "    words = word_tokenize(message)\r\n",
        "    for w in words:\r\n",
        "        all_words.append(w)\r\n",
        "        \r\n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-5w_EFHabVL",
        "outputId": "b56ca5cc-da09-432d-fe07-914282c01ab8"
      },
      "source": [
        "# print the total number of words and the 15 most common words\r\n",
        "print('Number of words: {}'.format(len(all_words)))\r\n",
        "print('Most common words: {}'.format(all_words.most_common(15)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words: 6579\n",
            "Most common words: [('numbr', 2648), ('u', 1207), ('call', 674), ('go', 456), ('get', 451), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 304), ('moneysymbnumbr', 303), ('ok', 293), ('free', 284), ('day', 276), ('know', 275), ('love', 266)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIwk8D2lad9Q"
      },
      "source": [
        "# use the 1500 most common words as features\r\n",
        "word_features = list(all_words.keys())[:1500]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5scmqAZsayTX",
        "outputId": "dcfff584-fffa-457c-e395-930a0ecd96d8"
      },
      "source": [
        "print(word_features)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['go', 'jurong', 'point', 'crazi', 'avail', 'bugi', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'got', 'amor', 'wat', 'ok', 'lar', 'joke', 'wif', 'u', 'oni', 'free', 'entri', 'numbr', 'wkli', 'comp', 'win', 'fa', 'cup', 'final', 'tkt', 'numbrst', 'may', 'text', 'receiv', 'question', 'std', 'txt', 'rate', 'c', 'appli', 'numbrovernumbr', 'dun', 'say', 'earli', 'hor', 'alreadi', 'nah', 'think', 'goe', 'usf', 'live', 'around', 'though', 'freemsg', 'hey', 'darl', 'week', 'word', 'back', 'like', 'fun', 'still', 'tb', 'xxx', 'chg', 'send', 'moneysymbnumbr', 'rcv', 'even', 'brother', 'speak', 'treat', 'aid', 'patent', 'per', 'request', 'mell', 'oru', 'minnaminungint', 'nurungu', 'vettam', 'set', 'callertun', 'caller', 'press', 'copi', 'friend', 'winner', 'valu', 'network', 'custom', 'select', 'receivea', 'prize', 'reward', 'claim', 'call', 'code', 'klnumbr', 'valid', 'hour', 'mobil', 'month', 'r', 'entitl', 'updat', 'latest', 'colour', 'camera', 'co', 'gon', 'na', 'home', 'soon', 'want', 'talk', 'stuff', 'anymor', 'tonight', 'k', 'cri', 'enough', 'today', 'six', 'chanc', 'cash', 'pound', 'cshnumbr', 'cost', 'numbrp', 'day', 'numbrday', 'tsandc', 'repli', 'hl', 'info', 'urgent', 'membership', 'jackpot', 'www', 'dbuk', 'net', 'lccltd', 'pobox', 'numbrldnwnumbranumbrrwnumbr', 'search', 'right', 'thank', 'breather', 'promis', 'wont', 'take', 'help', 'grant', 'fulfil', 'wonder', 'bless', 'time', 'date', 'sunday', 'xxxmobilemovieclub', 'use', 'credit', 'click', 'wap', 'link', 'next', 'messag', 'http', 'com', 'qjkgighjjgcbl', 'oh', 'watch', 'eh', 'rememb', 'spell', 'name', 'ye', 'v', 'naughti', 'make', 'wet', 'fine', 'way', 'feel', 'gota', 'b', 'england', 'macedonia', 'dont', 'miss', 'goal', 'team', 'news', 'ur', 'nation', 'eg', 'tri', 'wale', 'scotland', 'numbrtxt', 'únumbr', 'poboxoxnumbrwnumbrwq', 'serious', 'ha', 'ü', 'pay', 'first', 'da', 'stock', 'comin', 'aft', 'finish', 'lunch', 'str', 'lor', 'ard', 'smth', 'ffffffffff', 'alright', 'meet', 'sooner', 'forc', 'eat', 'slice', 'realli', 'hungri', 'tho', 'suck', 'mark', 'get', 'worri', 'know', 'sick', 'turn', 'pizza', 'lol', 'alway', 'convinc', 'catch', 'bu', 'fri', 'egg', 'tea', 'mom', 'left', 'dinner', 'love', 'amp', 'pack', 'car', 'let', 'room', 'ahhh', 'work', 'vagu', 'wait', 'clear', 'sure', 'sarcast', 'x', 'us', 'yeah', 'apologet', 'fallen', 'actin', 'spoilt', 'child', 'caught', 'till', 'badli', 'cheer', 'tell', 'anyth', 'fear', 'faint', 'housework', 'quick', 'cuppa', 'subscript', 'rington', 'uk', 'charg', 'pleas', 'confirm', 'yup', 'look', 'msg', 'xuhui', 'learn', 'numbrnd', 'lesson', 'numbram', 'oop', 'roommat', 'done', 'see', 'letter', 'decid', 'hello', 'saturday', 'tomo', 'invit', 'pl', 'ahead', 'watt', 'weekend', 'abiola', 'forget', 'need', 'crave', 'sweet', 'arabian', 'steed', 'mmmmmm', 'yummi', 'rodger', 'burn', 'sm', 'nokia', 'camcord', 'deliveri', 'tomorrow', 'hope', 'man', 'well', 'endow', 'lt', 'gt', 'inch', 'hep', 'immunis', 'nigeria', 'fair', 'tyler', 'could', 'mayb', 'ask', 'bit', 'stubborn', 'hospit', 'kept', 'weak', 'sucker', 'saw', 'class', 'gram', 'usual', 'run', 'half', 'eighth', 'smarter', 'almost', 'whole', 'second', 'fyi', 'ride', 'morn', 'crash', 'place', 'wow', 'never', 'realiz', 'embarass', 'accomod', 'thought', 'sinc', 'best', 'seem', 'happi', 'cave', 'sorri', 'give', 'offer', 'ac', 'sptv', 'new', 'jersey', 'devil', 'detroit', 'red', 'wing', 'play', 'ice', 'hockey', 'correct', 'incorrect', 'end', 'mallika', 'sherawat', 'yesterday', 'find', 'url', 'congrat', 'year', 'special', 'cinema', 'pass', 'suprman', 'matrixnumbr', 'starwarsnumbr', 'etc', 'bxnumbr', 'ipnumbr', 'numbrw', 'numbrpm', 'later', 'reach', 'gauti', 'sehwag', 'odi', 'seri', 'pick', 'burger', 'move', 'pain', 'kill', 'good', 'girl', 'situat', 'seeker', 'part', 'check', 'iq', 'took', 'forev', 'come', 'doubl', 'hair', 'dresser', 'said', 'wun', 'cut', 'short', 'nice', 'advis', 'follow', 'recent', 'review', 'mob', 'award', 'bonu', 'song', 'dedic', 'valuabl', 'frnd', 'rpli', 'complimentari', 'trip', 'eurodisinc', 'trav', 'aco', 'entrynumbr', 'di', 'morefrmmob', 'shracomorsglsuplt', 'lsnumbr', 'numbraj', 'hear', 'divorc', 'barbi', 'ken', 'plane', 'wah', 'lucki', 'save', 'money', 'hee', 'hi', 'babe', 'im', 'wan', 'someth', 'xx', 'perform', 'machan', 'that', 'cool', 'gentleman', 'digniti', 'respect', 'peopl', 'much', 'shi', 'pa', 'oper', 'job', 'ta', 'earn', 'ah', 'stop', 'urgnt', 'real', 'yo', 'ticket', 'one', 'jacket', 'multi', 'start', 'came', 'bed', 'coin', 'factori', 'nitro', 'ela', 'kano', 'il', 'download', 'wen', 'stand', 'close', 'anoth', 'night', 'spent', 'late', 'afternoon', 'casualti', 'mean', 'stuffnumbrmoro', 'includ', 'sheet', 'smile', 'pleasur', 'troubl', 'pour', 'rain', 'sumnumbr', 'hurt', 'becoz', 'someon', 'servic', 'repres', 'guarante', 'havent', 'plan', 'buy', 'lido', 'show', 'collect', 'simpli', 'password', 'mix', 'verifi', 'usher', 'britney', 'fml', 'po', 'box', 'mknumbr', 'numbrh', 'numbrppw', 'telugu', 'movi', 'abt', 'load', 'loan', 'wk', 'hol', 'forgot', 'hairdress', 'appoint', 'four', 'shower', 'beforehand', 'caus', 'prob', 'coffe', 'anim', 'noth', 'els', 'okay', 'price', 'long', 'legal', 'ave', 'am', 'gone', 'numbrth', 'drive', 'test', 'yet', 'guess', 'gave', 'boston', 'men', 'chang', 'locat', 'nyc', 'cuz', 'signin', 'page', 'umma', 'life', 'vava', 'lot', 'dear', 'wish', 'birthday', 'truli', 'memor', 'aight', 'hit', 'would', 'ip', 'address', 'consid', 'comput', 'minecraft', 'server', 'grumpi', 'old', 'better', 'lie', 'busi', 'plural', 'noun', 'research', 'thing', 'scare', 'mah', 'loud', 'gent', 'contact', 'last', 'draw', 'knumbr', 'numbrhr', 'numbrppm', 'wa', 'openin', 'sentenc', 'formal', 'anyway', 'juz', 'tt', 'eatin', 'puttin', 'weight', 'haha', 'anythin', 'happen', 'enter', 'cabin', 'boss', 'felt', 'askd', 'apart', 'went', 'holiday', 'flight', 'inc', 'min', 'goodo', 'must', 'friday', 'potato', 'ratio', 'tortilla', 'hmm', 'uncl', 'inform', 'school', 'directli', 'food', 'privat', 'account', 'statement', 'unredeem', 'identifi', 'expir', 'landlin', 'boxnumbrwrnumbrc', 'appl', 'pair', 'malarki', 'voda', 'number', 'match', 'quot', 'standard', 'app', 'sao', 'mu', 'predict', 'yetund', 'sent', 'bother', 'involv', 'impos', 'apologis', 'del', 'bak', 'sum', 'lucyxx', 'tmorrow', 'answer', 'sunshin', 'quiz', 'q', 'top', 'soni', 'dvd', 'player', 'countri', 'algarv', 'ansr', 'sp', 'tyron', 'laid', 'dog', 'direct', 'join', 'largest', 'bt', 'txting', 'gravel', 'nt', 'ecnumbra', 'emailaddress', 'befor', 'activ', 'chat', 'svc', 'hardcor', 'age', 'yr', 'lazi', 'type', 'lect', 'pouch', 'sir', 'mail', 'swt', 'nver', 'tire', 'littl', 'lovabl', 'person', 'coz', 'somtim', 'occupi', 'biggest', 'heart', 'gud', 'ninumbr', 'open', 'ya', 'dot', 'what', 'staff', 'randi', 'sexi', 'femal', 'local', 'luv', 'netcollex', 'ltd', 'ummma', 'begin', 'qatar', 'pray', 'hard', 'delet', 'sindu', 'birla', 'soft', 'wine', 'flow', 'thk', 'plaza', 'typic', 'everywher', 'dirt', 'floor', 'window', 'shirt', 'sometim', 'mouth', 'dream', 'without', 'chore', 'joy', 'tv', 'exist', 'hail', 'mist', 'becom', 'aaooooright', 'leav', 'hous', 'interview', 'boy', 'annonc', 'arrang', 'keep', 'safe', 'envi', 'everyon', 'parent', 'hand', 'excit', 'spend', 'bootydeli', 'f', 'bangbab', 'order', 'content', 'goto', 'bangb', 'internet', 'menu', 'cultur', 'modul', 'snumbr', 'avoid', 'missunderstd', 'wit', 'belov', 'escap', 'fanci', 'bridg', 'lager', 'complet', 'form', 'clark', 'also', 'utter', 'wast', 'axi', 'bank', 'hmmm', 'hop', 'muz', 'discuss', 'liao', 'bloodi', 'hell', 'cant', 'believ', 'surnam', 'mr', 'ill', 'clue', 'spanish', 'bath', 'carlo', 'mall', 'stay', 'til', 'smoke', 'moneysymb', 'worth', 'doesnt', 'log', 'spoke', 'maneesha', 'satisfi', 'experi', 'toll', 'lift', 'especi', 'approach', 'studi', 'grnumbr', 'trust', 'guy', 'bye', 'handsom', 'toward', 'mummi', 'boytoy', 'awesom', 'minut', 'freephon', 'xma', 'radio', 'ju', 'si', 'uniqu', 'august', 'areyouuniqu', 'leagu', 'touch', 'deal', 'cours', 'howev', 'suggest', 'abl', 'or', 'everi', 'stool', 'settl', 'wishin', 'mrng', 'hav', 'stori', 'hamster', 'dead', 'tmr', 'orchard', 'mrt', 'kate', 'babyjontet', 'found', 'enc', 'buck', 'darlin', 'ive', 'colleg', 'refil', 'success', 'inr', 'decim', 'keralacircl', 'prepaid', 'balanc', 'rs', 'transact', 'id', 'kr', 'goodmorn', 'sleep', 'ga', 'alter', 'dat', 'ericsson', 'oso', 'can', 'not', 'oredi', 'straight', 'dogg', 'connect', 'refund', 'bill', 'shoot', 'big', 'readi', 'bruv', 'break', 'semest', 'noe', 'leh', 'sound', 'head', 'slept', 'past', 'easi', 'sen', 'exam', 'march', 'atm', 'regist', 'os', 'ubandu', 'instal', 'disk', 'import', 'file', 'system', 'repair', 'shop', 'romant', 'nite', 'sceneri', 'tc', 'biz', 'numbroptout', 'numbrgbp', 'mtmsgnumbr', 'appreci', 'partner', 'career', 'flyng', 'horo', 'star', 'sign', 'g', 'ari', 'compani', 'elama', 'mudyadhu', 'strict', 'teacher', 'bcoz', 'teach', 'conduct', 'gandhipuram', 'walk', 'cross', 'road', 'side', 'street', 'rubber', 'batteri', 'die', 'flirt', 'sam', 'recd', 'thirtyeight', 'penc', 'print', 'upstair', 'closer', 'wil', 'theori', 'argument', 'lose', 'argu', 'kick', 'secret', 'admir', 'reveal', 'tomarrow', 'laptop', 'case', 'pleassssssseeeee', 'tel', 'avent', 'sportsx', 'shine', 'meant', 'although', 'told', 'baig', 'face', 'fr', 'thanx', 'everyth', 'commerci', 'websit', 'slipper', 'kalli', 'bat', 'inning', 'didnt', 'goodnight', 'fix', 'wake', 'dearli', 'congratul', 'cd', 'voucher', 'numbrgift', 'music', 'tnc', 'ldew', 'comnumbrwinnumbrppmxnumbragenumbr', 'ranjith', 'cal', 'drpd', 'deeraj', 'deepak', 'numbrmin', 'hold', 'bcum', 'angri', 'wid', 'dnt', 'childish', 'true', 'deep', 'affect', 'care', 'kettoda', 'manda', 'up', 'ship', 'numbrwk', 'usp', 'lag', 'bribe', 'nipost', 'lemm', 'necessarili', 'expect', 'headin', 'mmm', 'jolt', 'suzi', 'lover', 'video', 'handset', 'anytim', 'unlimit', 'park', 'mini', 'disturb', 'luton', 'ring', 'h', 'horni', 'nake', 'hot', 'unsubscrib', 'dint', 'wana', 'sometm', 'clubnumbrmobil', 'choos', 'club', 'clubnumbr', 'boxnumbr', 'numbrwt', 'evo', 'flash', 'jealou', 'singl', 'chart', 'qualiti', 'sort', 'narcot', 'sunni', 'ray', 'blue', 'bay', 'hmv', 'genuin', 'numbrperc', 'might', 'object', 'bf', 'rob', 'mack', 'gf', 'theater', 'celebr', 'full', 'swing', 'tool', 'definit', 'gdeve', 'far', 'oki', 'ahold', 'anybodi', 'throw', 'babi', 'cruisin', 'fone', 'jenni', 'ge', 'shall', 'tonit', 'varunnathu', 'edukkukaye', 'raksha', 'ollu', 'sens', 'gautham', 'haf', 'stupid', 'cam', 'buzi', 'accident', 'resend', 'phone', 'upgrad', 'sim', 'card', 'loyalti', 'numbrthfeb', 'unless', 'gurl', 'appropri', 'teas', 'plz', 'rose', 'grave', 'bslvyl', 'somebodi', 'high', 'diesel', 'shit', 'shock', 'scari', 'imagin', 'def', 'somewher', 'taxi', 'fridg', 'meal', 'womdarful', 'actor', 'blind', 'numbru', 'roddsnumbr', 'aberdeen', 'unit', 'kingdom', 'img', 'w', 'icmbnumbrcktznumbrrnumbr', 'hide', 'remb', 'book', 'jo', 'friendship', 'hang', 'thread', 'themob', 'newest', 'game', 'tone', 'gossip', 'sport', 'fit', 'funki', 'garag', 'key', 'bookshelf', 'accept', 'sister', 'dearnumbr', 'bestnumbr', 'closnumbr', 'lvblefrnd', 'jstfrnd', 'cutefrnd', 'lifpartnr', 'belovd', 'swtheart', 'bstfrnd', 'enemi', 'smart', 'weekli', 'cs', 'winnersclub', 'mnumbr', 'numbruz', 'gbpnumbr', 'normal', 'rest', 'mylif', 'wot', 'lost', 'made', 'advanc', 'pongal', 'kb', 'power', 'yoga', 'dunno', 'tahan', 'anot', 'lo', 'dude', 'afraid', 'decemb', 'numbrmth', 'cake', 'merri', 'christma', 'kiss', 'cud', 'ppl', 'gona', 'lnumbr', 'buse', 'waitin', 'pete', 'guild', 'bristol', 'problem', 'track', 'record', 'read', 'women', 'light', 'apo', 'return', 'immedi', 'germani', 'line', 'via', 'access', 'prepay', 'evapor', 'violat', 'privaci', 'steal', 'employ', 'paperwork', 'report', 'supervisor', 'valentin', 'lifetim', 'rcvd', 'custcar', 'daaaaa', 'dine', 'surf', 'post', 'wiv', 'carolin', 'favourit', 'stranger', 'interest', 'two', 'round', 'gudnit', 'practic', 'yiju', 'huim', 'num', 'small', 'prestig', 'shag', 'sextextuk', 'xxuk', 'jeremiah', 'iphon', 'apeshit', 'ever', 'misbehav', 'slap', 'urself', 'fault', 'basic', 'figur', 'alcohol', 'jay', 'weed', 'ish', 'ago', 'wtf', 'onam', 'sirji', 'met', 'insur', 'insha', 'allah', 'rakhesh', 'ex', 'tata', 'aig', 'tissco', 'tayseer', 'current', 'maxim', 'cc', 'hg', 'suitenumbr', 'numbrland', 'row', 'wnumbrjnumbrhl', 'unemploy', 'moment', 'st', 'andrew', 'cold', 'chikku', 'db', 'audrey', 'statu', 'forward', 'dawn', 'refresh', 'aliv', 'breath', 'air', 'z', 'update_now', 'motorola', 'sonyericsson', 'bluetooth', 'orang', 'mobileupdnumbr', 'callnumbroptout', 'fnumbrq', 'discount', 'rpnumbr', 'regalportfolio', 'uniform', 'geeee', 'woke', 'cuddl', 'spoil', 'agre', 'will', 'refer', 'tnumbr', 'gbp', 'seen', 'recognis', 'lindsay', 'sigh', 'bar', 'ptbo', 'heron', 'payasam', 'rinu', 'bring', 'taught', 'becau', 'he', 'project', 'prabu', 'mistak', 'bodi', 'quit', 'slow', 'guid', 'ovul', 'relax', 'reason', 'followin', 'coupl', 'wallet', 'numbrmonth', 'nnumbrdx', 'owl', 'lick', 'mm', 'rental', 'mobilesdirect', 'ornumbrstoptxt', 'huh', 'sat', 'intro', 'pilat', 'kickbox', 'offic', 'lap', 'shut', 'bout', 'numbrish', 'calcul', 'period', 'actual', 'rock', 'put', 'pictur', 'ass', 'facebook', 'al', 'salam', 'wahleykkum', 'share', 'grace', 'god', 'inshah', 'visitor', 'india', 'field', 'quickli', 'administr', 'poli', 'numbrxmoneysymbnumbrpw', 'emoneysymbnd', 'chechi', 'cream', 'none', 'yep', 'loxahatche', 'tree', 'stoner', 'slightli', 'disastr', 'pm', 'fav', 'wld', 'drink', 'busetop', 'sender', 'fullonsm', 'iron', 'yan', 'jiu', 'skip', 'den', 'blah', 'wendi', 'l', 'boxnumbrsknumbrch', 'whatsup', 'competit', 'txttowin', 'logo', 'namenumbr', 'mobno', 'adam', 'eve', 'yahoo', 'poboxnumbrwnumbrwq', 'txtno', 'ad', 'poboxnumbrnnumbrtfnumbrp', 'siva', 'hostel', 'aha', 'land', 'voic', 'express', 'sentiment', 'rowdi', 'ful', 'attitud']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkHHK9E6a61I",
        "outputId": "9b66451e-04d1-4476-f6ab-f160d424f598"
      },
      "source": [
        "# The find_features function will determine which of the 1500 word features are contained in the review\r\n",
        "def find_features(message):\r\n",
        "    words = word_tokenize(message)\r\n",
        "    features = {}\r\n",
        "    for word in word_features:\r\n",
        "        features[word] = (word in words)\r\n",
        "\r\n",
        "    return features\r\n",
        "\r\n",
        "features = find_features(processed[0])\r\n",
        "for key, value in features.items():\r\n",
        "    if value == True:\r\n",
        "        print (key)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go\n",
            "jurong\n",
            "point\n",
            "crazi\n",
            "avail\n",
            "bugi\n",
            "n\n",
            "great\n",
            "world\n",
            "la\n",
            "e\n",
            "buffet\n",
            "cine\n",
            "got\n",
            "amor\n",
            "wat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfJXB99Tb7Cm"
      },
      "source": [
        "#for all the messages\r\n",
        "messages = list(zip(processed, Y))\r\n",
        "\r\n",
        "# define a seed for reproducibility\r\n",
        "seed = 1\r\n",
        "np.random.seed = seed\r\n",
        "np.random.shuffle(messages)\r\n",
        "\r\n",
        "# call find_features function for each SMS message\r\n",
        "featuresets = [(find_features(text), label) for (text, label) in messages]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JA-E66xcUEV"
      },
      "source": [
        "from sklearn import model_selection\r\n",
        "\r\n",
        "# split the data into training and testing datasets\r\n",
        "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDjwWdAwcbnf",
        "outputId": "960a639a-99d5-4fe8-fb83-84f9443cee0f"
      },
      "source": [
        "print(len(training))\r\n",
        "print(len(testing))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4179\n",
            "1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pof0oP44ckd0"
      },
      "source": [
        "4.scikit-learn classifiers with nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLEVP_H1co1z",
        "outputId": "3e2c4dad-1af0-4d2c-b8f8-ac2b41929869"
      },
      "source": [
        "# We can use sklearn algorithms in NLTK\r\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "model = SklearnClassifier(SVC(kernel = 'linear'))\r\n",
        "\r\n",
        "# train the model on the training data\r\n",
        "model.train(training)\r\n",
        "\r\n",
        "# and test on the testing dataset!\r\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\r\n",
        "print(\"SVC Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC Accuracy: 98.63603732950466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izGQYRkQc4EW",
        "outputId": "f50d0b0d-c653-4b7a-9a76-654b2f838dce"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\r\n",
        "\r\n",
        "# Define models to train\r\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\r\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\r\n",
        "\r\n",
        "classifiers = [\r\n",
        "    KNeighborsClassifier(),\r\n",
        "    DecisionTreeClassifier(),\r\n",
        "    RandomForestClassifier(),\r\n",
        "    LogisticRegression(),\r\n",
        "    SGDClassifier(max_iter = 100),\r\n",
        "    MultinomialNB(),\r\n",
        "    SVC(kernel = 'linear')\r\n",
        "]\r\n",
        "\r\n",
        "models = zip(names, classifiers)\r\n",
        "\r\n",
        "for name, model in models:\r\n",
        "    nltk_model = SklearnClassifier(model)\r\n",
        "    nltk_model.train(training)\r\n",
        "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\r\n",
        "    print(\"{} Accuracy: {}\".format(name, accuracy))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K Nearest Neighbors Accuracy: 93.96984924623115\n",
            "Decision Tree Accuracy: 97.63101220387652\n",
            "Random Forest Accuracy: 98.34888729361091\n",
            "Logistic Regression Accuracy: 98.56424982053123\n",
            "SGD Classifier Accuracy: 98.42067480258436\n",
            "Naive Bayes Accuracy: 98.1335247666906\n",
            "SVM Linear Accuracy: 98.63603732950466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyAcj6UzdUW2",
        "outputId": "d155bdaf-80bf-4e06-9195-9bd4a51fcc5e"
      },
      "source": [
        "# Ensemble methods - Voting classifier\r\n",
        "from sklearn.ensemble import VotingClassifier\r\n",
        "\r\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\r\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\r\n",
        "\r\n",
        "classifiers = [\r\n",
        "    KNeighborsClassifier(),\r\n",
        "    DecisionTreeClassifier(),\r\n",
        "    RandomForestClassifier(),\r\n",
        "    LogisticRegression(),\r\n",
        "    SGDClassifier(max_iter = 100),\r\n",
        "    MultinomialNB(),\r\n",
        "    SVC(kernel = 'linear')\r\n",
        "]\r\n",
        "\r\n",
        "models = list(zip(names, classifiers))\r\n",
        "\r\n",
        "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\r\n",
        "nltk_ensemble.train(training)\r\n",
        "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\r\n",
        "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Voting Classifier: Accuracy: 98.63603732950466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_VFVGzddnxK"
      },
      "source": [
        "# make class label prediction for testing set\r\n",
        "txt_features, labels = zip(*testing)\r\n",
        "\r\n",
        "prediction = nltk_ensemble.classify_many(txt_features)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "WbJu1I85dxSy",
        "outputId": "29b0c675-b9ce-4624-ea43-536ed921bf4b"
      },
      "source": [
        "# print a confusion matrix and a classification report\r\n",
        "print(classification_report(labels, prediction))\r\n",
        "\r\n",
        "pd.DataFrame(\r\n",
        "    confusion_matrix(labels, prediction),\r\n",
        "    index = [['actual', 'actual'], ['ham', 'spam']],\r\n",
        "    columns = [['predicted', 'predicted'], ['ham', 'spam']])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1210\n",
            "           1       1.00      0.89      0.94       183\n",
            "\n",
            "    accuracy                           0.99      1393\n",
            "   macro avg       0.99      0.95      0.97      1393\n",
            "weighted avg       0.99      0.99      0.99      1393\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>ham</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
              "      <th>ham</th>\n",
              "      <td>1210</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spam</th>\n",
              "      <td>20</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            predicted     \n",
              "                  ham spam\n",
              "actual ham       1210    0\n",
              "       spam        20  163"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdj0ZDvuezDc"
      },
      "source": [
        "#20 times when we predicted ham, it was actually spam. 0 times it was ham, 163 times it was spam , 0.99 accuracy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}